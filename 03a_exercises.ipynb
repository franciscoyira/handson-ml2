{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cb3d1b-bb67-4a44-a845-4c562530344a",
   "metadata": {},
   "source": [
    "# Exercises chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e38e2f1-7c95-479a-ac9e-a6a6e94e6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Helper function to save the images\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd57f6-786e-4d28-a0a4-8d5c815e949b",
   "metadata": {},
   "source": [
    "1. Build a MINST classifier with 97% accuracy on test set \n",
    "Hint: use `KNeighborsClassifier` and do grid search over hyperparameters (`weights` and `n_neighbors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162b0a1e-6015-412f-94e1-f63a55c50d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the famous MINST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c074d8e2-298d-4176-ae66-8599f06a0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing + splitting into test and train\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8) #converting response variable to integer\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd72d549-ba9f-48b3-9a8c-7cce62474008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "my_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c7c545-a1aa-4269-97b4-13a3c2bd872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search over hyperparameters (weights and n_neighbors)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_knn = {\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'n_neighbors': list(range(1, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8005d4a-25cc-460b-8984-0f08eba0616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(my_knn, param_grid_knn, cv = 5, scoring = 'accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40a9bf7-5b2f-4a4a-8c61-ebc976f1514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716166666666666\n",
      "{'n_neighbors': 4, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=4, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "# Source of the code: https://www.ritchieng.com/machine-learning-efficiently-search-tuning-param/ \n",
    "# Single best score achieved across all params (k)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (k) used to generate that score\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d81053-5e37-4ab6-95b7-b2efc57c6b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting the model with the best parameters\n",
    "optimal_knn = KNeighborsClassifier(\n",
    "    n_neighbors=4, \n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "optimal_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631f7f00-d44e-4252-a237-2089428d8706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate *accuracy* on test data\n",
    "y_knn_pred = optimal_knn.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1917b24-7b85-428a-875a-718618dcba6a",
   "metadata": {},
   "source": [
    "2. Writing function that shifts images, then using it to augment the dataset and train the model on the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fea67e8-7e26-4cd6-9e08-5fb21cebe486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import shift\n",
    "\n",
    "#Example:\n",
    "#shift(image, [2, 1], cval=0) shifts the image 2 pixels down and 1 pixel to the right\n",
    "\n",
    "# Creating the function\n",
    "def shift_image(image, direction):    \n",
    "    if direction == 'left':\n",
    "        shifting_arr = [0, -1]\n",
    "    elif direction == 'right':\n",
    "        shifting_arr = [0, 1]\n",
    "    elif direction == 'up':\n",
    "        shifting_arr = [-1, 0]\n",
    "    elif direction == 'down':\n",
    "        shifting_arr = [1, 0]\n",
    "        \n",
    "    return(shift(image.reshape(28, 28), shifting_arr, cval=0))\n",
    "\n",
    "# How can I access an image?? Look for an example\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8cf54a3-ea3b-4528-a802-0ca908afb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting the dataset\n",
    "x_up = np.array([shift_image(x, direction='up') for x in X_train])\n",
    "x_down = np.array([shift_image(x, direction='down') for x in X_train])\n",
    "x_right = np.array([shift_image(x, direction='right') for x in X_train])\n",
    "x_left = np.array([shift_image(x, direction='left') for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2eebd3c-ebe0-4e3b-b7ac-bb57feaf7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enlarged = np.concatenate(\n",
    "    (X_train,\n",
    "    x_up.reshape(60000, 784),\n",
    "    x_down.reshape(60000, 784),\n",
    "    x_right.reshape(60000, 784),\n",
    "    x_left.reshape(60000, 784))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04af4f4f-75bc-4249-9cc4-de24f88f046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge y too!\n",
    "# np.tile(np.array([1,2]), 2)\n",
    "y_enlarged = np.tile(y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a97504c0-a032-425c-843b-9c82f2ab5fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train the model!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "optimal_knn2 = KNeighborsClassifier(\n",
    "    n_neighbors=4, \n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "optimal_knn2.fit(X_enlarged, y_enlarged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffcfae0c-f8f9-4bd4-b3d9-8493ae75eef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate *accuracy* on test data\n",
    "y_knn2_pred = optimal_knn2.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_knn2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a42db1-2984-49f1-9759-097ab17d3687",
   "metadata": {},
   "source": [
    "The accuracy improved, but just a little bit. BTW, it's literally the same metric value that appears on the solutions, so my solution is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bdc0e-1071-41f0-9e3c-5b2890672b0e",
   "metadata": {},
   "source": [
    "3. Tackle the Titatnic dataset. The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dd7913a-66e9-4638-89cb-bd0c02b60e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "import urllib.request\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\"\n",
    "\n",
    "def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for filename in (\"train.csv\", \"test.csv\"):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            print(\"Downloading\", filename)\n",
    "            urllib.request.urlretrieve(url + filename, filepath)\n",
    "\n",
    "fetch_titanic_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc780dc3-8ef6-4343-a8e5-1118b949ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5288cbd9-9ff4-4efc-b74f-856c8103ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35fae546-b4b0-4a71-9bc6-e63a57a019a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d435cbe-830a-4c58-8430-5d4520fd3eed",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **PassengerId**: a unique identifier for each passenger\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6d69f-b8f6-4500-9576-3ebf0d267e8f",
   "metadata": {},
   "source": [
    "Let's explicitly set the `PassengerId` column as the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53f2160e-f7dc-47ba-a554-dde7e7962d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a51f7d42-d65b-4160-a92e-af844916692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4069d8-3171-4adf-b970-05ecdcba71fa",
   "metadata": {},
   "source": [
    "It's better to ignore Name and Ticket because it's difficult to convert them into useful information. \n",
    "It's necessary to implemennt an imputation strategy for Age missing values. Idea: input the median according to Sex and Pclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9285c6e-348d-4949-a9a8-d73f6186ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(\"Survived\" ,axis= 1)\n",
    "y_train = train_data.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffa10c97-60ba-4a5f-af33-3a9896ce82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Name      891 non-null    object \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Ticket    891 non-null    object \n",
      " 7   Fare      891 non-null    float64\n",
      " 8   Cabin     204 non-null    object \n",
      " 9   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32bb1812-e5cb-4669-a379-d22268ca58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_attribs = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "num_indexes = X_train.columns.get_indexer(num_attribs)\n",
    "cat_attribs = ['Sex', 'Embarked', 'Pclass']\n",
    "cat_indexes = X_train.columns.get_indexer(cat_attribs)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    #('imputer', GroupImputer(group_cols = ['Sex', 'Pclass'], target = \"Age\", metric=\"median\")),\n",
    "    #('imputer2', GroupImputer(group_cols = ['Sex', 'Pclass'], target = \"Fare\", metric=\"median\")),\n",
    "    (\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", num_indexes)\n",
    "    ], remainder=\"drop\")),\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", cat_indexes)\n",
    "    ], remainder=\"drop\")),\n",
    "                        ('oneHot',OneHotEncoder(categories='auto'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5f916d4-0e9a-476d-b5d6-73900c632b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pipeline for numeric and pipeline for categorical\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline)])\n",
    "\n",
    "X_train2 = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad8a9f-655a-4cbf-ad10-f9809f67970d",
   "metadata": {},
   "source": [
    "At this point, I have succesfully:\n",
    "- Imputed missing values based on group means\n",
    "- Scaled numeric features\n",
    "- One-hot-encoded categorical variables\n",
    "\n",
    "Next: do `RandomSearchCV` with Random Forest model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d87e98c-1c67-4273-bbb2-9e36241332eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clas = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa1c18-3923-4ae0-a210-b39f1663951b",
   "metadata": {},
   "source": [
    "Looking at default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0855c2a8-bce6-4a49-b486-84156df7caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(forest_clas.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07e8c784-3cc1-40a6-89c8-06d278c90226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Tutorial I followed here: \n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 15)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(6, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74eeccae-132c-430c-afc1-407acbf0edac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [6, 16, 26, 37, 47, 58, 68,\n",
       "                                                      78, 89, 99, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 235, 371, 507,\n",
       "                                                         642, 778, 914, 1050,\n",
       "                                                         1185, 1321, 1457, 1592,\n",
       "                                                         1728, 1864, 2000]},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = forest_clas,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100,\n",
    "                               cv = 5,\n",
    "                               verbose=1,\n",
    "                               random_state=42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d56db9bb-118d-4bc5-83f1-02b29d1138ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 778,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 58,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43ce4b-b248-415f-b482-b0b93797dbd7",
   "metadata": {},
   "source": [
    "Now I can narrow down the hyperparameter search around the parameters found with `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13d2e5cc-5f81-4472-88c2-773c4e8a7811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8339150084740444"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "addd54e0-c748-431b-96f0-acf13bbed5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 375 candidates, totalling 1875 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [56, 57, 58, 59, 60],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [760, 770, 780, 790, 800]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [56, 57, 58, 59, 60],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [3, 4, 5, 6, 7],\n",
    "    'n_estimators': [760, 770, 780, 790, 800]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = forest_clas, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 1)\n",
    "\n",
    "grid_search.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce41fce5-5ca1-4f93-9e79-d7fbaa083c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 56,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 770}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42aeb4b6-c76c-4a09-88cb-5b0d656ea6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8339150084740444"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84ee7b4f-e309-41a7-9480-24e8cf38b799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=56, min_samples_split=5, n_estimators=770,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I should train the model on the whole training dataset\n",
    "final_rf = RandomForestClassifier(random_state=42)\n",
    "final_rf.set_params(**grid_search.best_params_)\n",
    "\n",
    "final_rf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33ff2714-4f68-4a59-9ee9-84f490be3cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Name      418 non-null    object \n",
      " 2   Sex       418 non-null    object \n",
      " 3   Age       332 non-null    float64\n",
      " 4   SibSp     418 non-null    int64  \n",
      " 5   Parch     418 non-null    int64  \n",
      " 6   Ticket    418 non-null    object \n",
      " 7   Fare      417 non-null    float64\n",
      " 8   Cabin     91 non-null     object \n",
      " 9   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 35.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae2e9fc4-2ef8-4281-95d7-ee10c1e213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = full_pipeline.transform(test_data)\n",
    "y_pred = final_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce5c3bf4-4b00-498a-84e3-364ec4c3fd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e9007db-a152-4637-ae9f-11cdc310b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PassengerId\n",
    "passengerid = test_data.reset_index().PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6125a63-6122-4c95-9e8f-8f5bf46242be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(passengerid[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8fdc507-4370-4323-b312-919695537345",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Survived':y_pred}\n",
    " \n",
    "# Creates pandas DataFrame.\n",
    "df = pd.DataFrame(data, index = passengerid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17266ad9-0adc-44ce-91e1-d64ab95ef895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outputs/titanic_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2797f6-93ac-41ae-9819-9c384acd8d3d",
   "metadata": {},
   "source": [
    "How could I improve this?\n",
    "\n",
    "- Use SVM instead\n",
    "- Better imputation of NAs\n",
    "- Better hyperparamter search\n",
    "- Turn elements of the data pre-processing into hyperparameters\n",
    "- Create ranges or categorical values with some of the numerical variables\n",
    "- Try to extract some useful information from the names? e.g. common names?\n",
    "- Use first letter of Cabin as a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48381e8c-450b-41df-bf0a-b2d659b13518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
