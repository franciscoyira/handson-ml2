{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cb3d1b-bb67-4a44-a845-4c562530344a",
   "metadata": {},
   "source": [
    "# Exercises chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e38e2f1-7c95-479a-ac9e-a6a6e94e6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Helper function to save the images\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd57f6-786e-4d28-a0a4-8d5c815e949b",
   "metadata": {},
   "source": [
    "1. Build a MINST classifier with 97% accuracy on test set \n",
    "Hint: use `KNeighborsClassifier` and do grid search over hyperparameters (`weights` and `n_neighbors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162b0a1e-6015-412f-94e1-f63a55c50d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the famous MINST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c074d8e2-298d-4176-ae66-8599f06a0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing + splitting into test and train\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8) #converting response variable to integer\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd72d549-ba9f-48b3-9a8c-7cce62474008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "my_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c7c545-a1aa-4269-97b4-13a3c2bd872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search over hyperparameters (weights and n_neighbors)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_knn = {\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'n_neighbors': list(range(1, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8005d4a-25cc-460b-8984-0f08eba0616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(my_knn, param_grid_knn, cv = 5, scoring = 'accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40a9bf7-5b2f-4a4a-8c61-ebc976f1514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716166666666666\n",
      "{'n_neighbors': 4, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=4, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "# Source of the code: https://www.ritchieng.com/machine-learning-efficiently-search-tuning-param/ \n",
    "# Single best score achieved across all params (k)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (k) used to generate that score\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d81053-5e37-4ab6-95b7-b2efc57c6b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting the model with the best parameters\n",
    "optimal_knn = KNeighborsClassifier(\n",
    "    n_neighbors=4, \n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "optimal_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631f7f00-d44e-4252-a237-2089428d8706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate *accuracy* on test data\n",
    "y_knn_pred = optimal_knn.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1917b24-7b85-428a-875a-718618dcba6a",
   "metadata": {},
   "source": [
    "2. Writing function that shifts images, then using it to augment the dataset and train the model on the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fea67e8-7e26-4cd6-9e08-5fb21cebe486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import shift\n",
    "\n",
    "#Example:\n",
    "#shift(image, [2, 1], cval=0) shifts the image 2 pixels down and 1 pixel to the right\n",
    "\n",
    "# Creating the function\n",
    "def shift_image(image, direction):    \n",
    "    if direction == 'left':\n",
    "        shifting_arr = [0, -1]\n",
    "    elif direction == 'right':\n",
    "        shifting_arr = [0, 1]\n",
    "    elif direction == 'up':\n",
    "        shifting_arr = [-1, 0]\n",
    "    elif direction == 'down':\n",
    "        shifting_arr = [1, 0]\n",
    "        \n",
    "    return(shift(image.reshape(28, 28), shifting_arr, cval=0))\n",
    "\n",
    "# How can I access an image?? Look for an example\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8cf54a3-ea3b-4528-a802-0ca908afb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting the dataset\n",
    "x_up = np.array([shift_image(x, direction='up') for x in X_train])\n",
    "x_down = np.array([shift_image(x, direction='down') for x in X_train])\n",
    "x_right = np.array([shift_image(x, direction='right') for x in X_train])\n",
    "x_left = np.array([shift_image(x, direction='left') for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2eebd3c-ebe0-4e3b-b7ac-bb57feaf7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enlarged = np.concatenate(\n",
    "    (X_train,\n",
    "    x_up.reshape(60000, 784),\n",
    "    x_down.reshape(60000, 784),\n",
    "    x_right.reshape(60000, 784),\n",
    "    x_left.reshape(60000, 784))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04af4f4f-75bc-4249-9cc4-de24f88f046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge y too!\n",
    "# np.tile(np.array([1,2]), 2)\n",
    "y_enlarged = np.tile(y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a97504c0-a032-425c-843b-9c82f2ab5fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train the model!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "optimal_knn2 = KNeighborsClassifier(\n",
    "    n_neighbors=4, \n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "optimal_knn2.fit(X_enlarged, y_enlarged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffcfae0c-f8f9-4bd4-b3d9-8493ae75eef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate *accuracy* on test data\n",
    "y_knn2_pred = optimal_knn2.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_knn2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a42db1-2984-49f1-9759-097ab17d3687",
   "metadata": {},
   "source": [
    "The accuracy improved, but just a little bit. BTW, it's literally the same metric value that appears on the solutions, so my solution is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bdc0e-1071-41f0-9e3c-5b2890672b0e",
   "metadata": {},
   "source": [
    "3. Tackle the Titatnic dataset. The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd7913a-66e9-4638-89cb-bd0c02b60e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "import urllib.request\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\"\n",
    "\n",
    "def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for filename in (\"train.csv\", \"test.csv\"):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            print(\"Downloading\", filename)\n",
    "            urllib.request.urlretrieve(url + filename, filepath)\n",
    "\n",
    "fetch_titanic_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc780dc3-8ef6-4343-a8e5-1118b949ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5288cbd9-9ff4-4efc-b74f-856c8103ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fae546-b4b0-4a71-9bc6-e63a57a019a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d435cbe-830a-4c58-8430-5d4520fd3eed",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **PassengerId**: a unique identifier for each passenger\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6d69f-b8f6-4500-9576-3ebf0d267e8f",
   "metadata": {},
   "source": [
    "Let's explicitly set the `PassengerId` column as the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f2160e-f7dc-47ba-a554-dde7e7962d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51f7d42-d65b-4160-a92e-af844916692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4069d8-3171-4adf-b970-05ecdcba71fa",
   "metadata": {},
   "source": [
    "It's better to ignore Name and Ticket because it's difficult to convert them into useful information. \n",
    "It's necessary to implemennt an imputation strategy for Age missing values. Idea: input the median according to Sex and Pclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9285c6e-348d-4949-a9a8-d73f6186ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1) INPUT MISSING VALUES, 2) SCALE, 3) ONE-HOT-ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4ee64e-1ef4-4d03-8397-4b6c9bfaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value imputation according to group mean \n",
    "# Here I should use the fit_transform thing\n",
    "'''\n",
    "imputer = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    add_indicator=True,\n",
    "    strategy=\"median\"\n",
    ")\n",
    "'''\n",
    "# But I have to code a custom Imputer\n",
    "# https://towardsdatascience.com/coding-a-custom-imputer-in-scikit-learn-31bd68e541de \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class GroupImputer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class used for imputing missing values in a pd.DataFrame using either mean or median of a group.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    group_cols : list\n",
    "        List of columns used for calculating the aggregated value \n",
    "    target : str\n",
    "        The name of the column to impute\n",
    "    metric : str\n",
    "        The metric to be used for remplacement, can be one of ['mean', 'median']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : array-like\n",
    "        The array with imputed values in the target column\n",
    "    '''\n",
    "    def __init__(self, group_cols, target, metric='mean'):\n",
    "        \n",
    "        assert metric in ['mean', 'median'], 'Unrecognized value for metric, should be mean/median'\n",
    "        assert type(group_cols) == list, 'group_cols should be a list of columns'\n",
    "        assert type(target) == str, 'target should be a string'\n",
    "        \n",
    "        self.group_cols = group_cols\n",
    "        self.target = target\n",
    "        self.metric = metric\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        assert pd.isnull(X[self.group_cols]).any(axis=None) == False, 'There are missing values in group_cols'\n",
    "        \n",
    "        impute_map = X.groupby(self.group_cols)[self.target].agg(self.metric) \\\n",
    "                                                            .reset_index(drop=False)\n",
    "        \n",
    "        self.impute_map_ = impute_map\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # make sure that the imputer was fitted\n",
    "        check_is_fitted(self, 'impute_map_')\n",
    "        \n",
    "        X = X.copy()\n",
    "        \n",
    "        for index, row in self.impute_map_.iterrows():\n",
    "            ind = (X[self.group_cols] == row[self.group_cols]).all(axis=1)\n",
    "            X.loc[ind, self.target] = X.loc[ind, self.target].fillna(row[self.target])\n",
    "        \n",
    "        return X.values\n",
    "    \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32bb1812-e5cb-4669-a379-d22268ca58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = ['Survived', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "num_indexes = train_data.columns.get_indexer(num_attribs)\n",
    "cat_attribs = ['Sex', 'Embarked', 'Pclass']\n",
    "cat_indexes = train_data.columns.get_indexer(cat_attribs)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', GroupImputer(group_cols = ['Sex', 'Pclass'], target = \"Age\", metric=\"median\")),\n",
    "    (\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", num_indexes)\n",
    "    ], remainder=\"drop\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", cat_indexes)\n",
    "    ], remainder=\"drop\")),\n",
    "                        ('oneHot',OneHotEncoder(categories='auto'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5f916d4-0e9a-476d-b5d6-73900c632b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pipeline for numeric and pipeline for categorical\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline)])\n",
    "\n",
    "\n",
    "fp_result= full_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d87e98c-1c67-4273-bbb2-9e36241332eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<891x14 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd033d3-7370-4d57-b120-c7ef8d8eac19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 6, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns.get_indexer(num_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290f465-685b-4d63-b901-c4e25e8946a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
